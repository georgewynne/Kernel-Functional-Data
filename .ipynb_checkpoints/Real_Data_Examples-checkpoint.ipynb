{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these (except TQDM) are standard imports and are included for example in Anaconda\n",
    "# TQDM is a package for progress bars and can be easily installed, see https://pypi.org/project/tqdm/\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "import scipy.linalg as lin\n",
    "from scipy.special import zeta\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import sklearn.gaussian_process as gp\n",
    "from scipy.stats import t\n",
    "from scipy.stats import percentileofscore \n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm Functions and T Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next two cells contain the code for the five different settings used in the numerical tests: ID, CEXP, FPCA, POLY and SQR. \n",
    "\n",
    "### To see how to combine these to recreate the numerical results see comments in the cells which perform the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_ID(X,Y,gamma=1):\n",
    "    \"\"\"\n",
    "    Forms the kernel matrix K for the two sample test using the SE-T kernel with bandwidth gamma\n",
    "    where T is the identity operator\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of samples from the first distribution \n",
    "    Y - (n_samples,n_obs) array of samples from the second distribution \n",
    "    gamma - bandwidth for the kernel, if -1 then median heuristic is used to pick gamma\n",
    "    \n",
    "    Returns:\n",
    "    K - matrix formed from the kernel values of all pairs of samples from the two distributions\n",
    "    \"\"\"\n",
    "    n_obs = X.shape[1]\n",
    "    XY = np.vstack((X,Y))\n",
    "    dist_mat = (1/np.sqrt(n_obs))*pairwise_distances(XY, metric='euclidean')\n",
    "    if gamma == -1:\n",
    "        gamma = np.median(dist_mat[dist_mat > 0])\n",
    "    K = np.exp(-0.5*(1/gamma**2)*(dist_mat**2))\n",
    "    return K\n",
    "\n",
    "def FPCA(X,n_comp = 0.95):\n",
    "    \"\"\"\n",
    "    Computes principal components of given data up to a specified explained variance level\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of function values\n",
    "    n_comp - number of principal components to compute. If in (0,1) then it is the explained variance level\n",
    "    \n",
    "    Returns:\n",
    "    Normalised eigenvalues and eigenfunctions\n",
    "    \"\"\"\n",
    "    n_points = np.shape(X)[1]\n",
    "    pca = PCA(n_components = n_comp)\n",
    "    pca.fit(X)\n",
    "    return (1/n_points)*pca.explained_variance_,pca.components_\n",
    "\n",
    "def K_FPCA(X,Y,gamma = 1,n_comp = 0.95):\n",
    "    \"\"\"\n",
    "    Forms the kernel matrix K for the two sample test using the SE-T kernel with bandwidth gamma\n",
    "    where T is the FPCA decomposition operator\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of samples from the first distribution \n",
    "    Y - (n_samples,n_obs) array of samples from the second distribution \n",
    "    gamma - bandwidth for the kernel, if -1 then median heuristic is used to pick gamma\n",
    "    n_comp - number of principal components to compute. If in (0,1) then it is the explained variance level\n",
    "    \n",
    "    Returns:\n",
    "    K - matrix formed from the kernel values of all pairs of samples from the two distributions\n",
    "    \"\"\"\n",
    "    n_obs = X.shape[1]\n",
    "    XY = np.vstack((X,Y))\n",
    "    e_vals,e_funcs = FPCA(XY,n_comp = n_comp)\n",
    "    scaled_e_funcs = e_funcs*np.sqrt(e_vals[:,np.newaxis])\n",
    "    XY_e = (1/n_obs)*np.dot(XY,scaled_e_funcs.T)\n",
    "    dist_mat = pairwise_distances(XY_e,metric='euclidean')\n",
    "    if gamma == -1:\n",
    "        gamma = np.median(dist_mat[dist_mat > 0])\n",
    "    K = np.exp(-0.5*(1/gamma**2)*(dist_mat**2))\n",
    "    return K\n",
    "\n",
    "def K_SQR(X,Y,gamma = 1):\n",
    "    \"\"\"\n",
    "    Forms the kernel matrix K for the two sample test using the SE-T kernel with bandwidth gamma\n",
    "    where T is the map which sends x -> (x,x^{2}) in the Cartesian product of L^{2} with itself.\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of samples from the first distribution \n",
    "    Y - (n_samples,n_obs) array of samples from the second distribution \n",
    "    gamma - bandwidth for the kernel to be used on the two norms, if -1 then median heuristic \n",
    "            is used to pick a different gamma for each norm, if gamma = 0 then median heuristic\n",
    "            is used to pick a single gamma for each norm.\n",
    "            \n",
    "    Returns:\n",
    "    K - matrix formed from the kernel values of all pairs of samples from the two distributions\n",
    "    \"\"\"\n",
    "    n_obs = X.shape[1]\n",
    "    XY = np.vstack((X,Y))\n",
    "    dist_mat_1 = (1/np.sqrt(n_obs))*pairwise_distances(XY, metric='euclidean')\n",
    "    dist_mat_2 = (1/np.sqrt(n_obs))*pairwise_distances(XY**2, metric='euclidean')\n",
    "    dist_mat = dist_mat_1 + dist_mat_2\n",
    "    if gamma == 0:\n",
    "        gamma = np.median(dist_mat[dist_mat > 0])\n",
    "        K = np.exp(-0.5*(1/gamma**2)*dist_mat**2)\n",
    "        return K\n",
    "    if gamma == -1:\n",
    "        gamma_1 = np.median(dist_mat_1[dist_mat_1 > 0])\n",
    "        gamma_2 = np.median(dist_mat_2[dist_mat_2 > 0])\n",
    "        K = np.exp(-0.5*((1/gamma_1**2)*dist_mat_1**2 + (1/gamma_2**2)*dist_mat_2**2))\n",
    "        return K\n",
    "    K = np.exp(-0.5*((1/gamma**2)*(dist_mat**2)))\n",
    "    return K\n",
    "\n",
    "def K_COV(X,Y,gamma=1):\n",
    "    \"\"\"\n",
    "    Forms the kernel matrix K for the two sample test using the COV kernel\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of samples from the first distribution \n",
    "    Y - (n_samples,n_obs) array of samples from the second distribution \n",
    "    gamma - dummy variable noot used in function, is an input for ease of compatability with other kernels\n",
    "    \n",
    "    Returns:\n",
    "    K - matrix formed from the kernel values of all pairs of samples from the two distributions\n",
    "    \"\"\"    \n",
    "    n_obs = X.shape[1]\n",
    "    XY = np.vstack((X,Y))\n",
    "    return ((1/n_obs)*np.dot(XY,XY.T))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_exp_kernel(x,y,n_freqs = 5,l=1):\n",
    "    \"\"\"\n",
    "    The c-exp kernel\n",
    "    \n",
    "    Parameters:\n",
    "    x,y - inputs \n",
    "    n_freqs - number of frequencies to include in the sum\n",
    "    l- bandwidth of the kernel\n",
    "    \n",
    "    Returns:\n",
    "    Kernel values given x,y\n",
    "    \"\"\"\n",
    "    \n",
    "    cos_term = np.sum([np.cos(2*np.pi*n*(x-y)) for n in range(n_freqs)])\n",
    "    return cos_term*np.exp(-(0.5/(l**2))*(x-y)**2)\n",
    "\n",
    "def CEXP(X,n_freqs = 20,l=np.sqrt(10)):\n",
    "    \"\"\"\n",
    "    Transforms an array of function values using the integral operator induced by the cos-exp kernel. \n",
    "    The function values are assumed to be on [0,1]\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of function values\n",
    "    n_freqs - number of frequencies to include in the sum\n",
    "    l- bandwidth of the kernel\n",
    "    \n",
    "    Returns:\n",
    "    cos_exp_X - (n_samples,n_obs) array of function values where each function has been passed\n",
    "                through the integral operator induced by the cos-exp kernel\n",
    "    \"\"\"\n",
    "    n_obs = X.shape[1]\n",
    "    obs_grid = np.linspace(0,1,n_obs)\n",
    "    T_mat = pairwise_kernels(obs_grid.reshape(-1,1), metric = cos_exp_kernel, n_freqs = n_freqs,l=l)\n",
    "    cos_exp_X = (1./n_obs)*np.dot(X,T_mat)\n",
    "    return cos_exp_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next three cells contain the functions used to conduct the two sample test.\n",
    "\n",
    "### MMD_K calculates an empirical MMD quantity \n",
    "\n",
    "### two_sample_test performs a two-sample test, using MMD_K multiple times\n",
    "\n",
    "### power_test performs two_sample_test numerous times to calculate an estimate of test power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_K(K,M,N):\n",
    "    \"\"\"\n",
    "    Calculates the empirical MMD^{2} given a kernel matrix computed from the samples and the sample sizes of each distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    K - kernel matrix of all pairwise kernel values of the two distributions\n",
    "    M - number of samples from first distribution\n",
    "    N - number of samples from first distribution\n",
    "    \n",
    "    Returns:\n",
    "    MMDsquared - empirical estimate of MMD^{2}\n",
    "    \"\"\"\n",
    "    \n",
    "    Kxx = K[:N,:N]\n",
    "    Kyy = K[N:,N:]\n",
    "    Kxy = K[:N,N:]\n",
    "    \n",
    "    t1 = (1./(M*(M-1)))*np.sum(Kxx - np.diag(np.diagonal(Kxx)))\n",
    "    t2 = (2./(M*N)) * np.sum(Kxy)\n",
    "    t3 = (1./(N*(N-1)))* np.sum(Kyy - np.diag(np.diagonal(Kyy)))\n",
    "    \n",
    "    MMDsquared = (t1-t2+t3)\n",
    "    \n",
    "    return MMDsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_test(X,Y,gamma,n_perms,z_alpha = 0.05,make_K = K_ID,return_p = False):\n",
    "    \"\"\"\n",
    "    Performs the two sample test and returns an accept or reject statement\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of samples from the first distribution \n",
    "    Y - (n_samples,n_obs) array of samples from the second distribution \n",
    "    gamma - bandwidth for the kernel\n",
    "    n_perms - number of permutations performed when bootstrapping the null\n",
    "    z_alpha - rejection threshold of the test\n",
    "    return_p - option to return the p-value of the test\n",
    "    make_K - function called to construct the kernel matrix used to compute the empirical MMD\n",
    "    \n",
    "    Returns:\n",
    "    rej - 1 if null rejected, 0 if null accepted\n",
    "    p-value - p_value of test\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples of each distribution is identified and kernel matrix formed\n",
    "    M = X.shape[0]\n",
    "    N = Y.shape[0]\n",
    "    K = make_K(X,Y,gamma = gamma)\n",
    "    \n",
    "    # Empirical MMD^{2} calculated\n",
    "    MMD_test = MMD_K(K,M,N)\n",
    "    \n",
    "    # For n_perms repeats the kernel matrix is shuffled and empirical MMD^{2} recomputed\n",
    "    # to simulate the null\n",
    "    shuffled_tests = np.zeros(n_perms)\n",
    "    for i in range(n_perms):\n",
    "            idx = np.random.permutation(M+N)\n",
    "            K = K[idx, idx[:, None]]\n",
    "            shuffled_tests[i] = MMD_K(K,M,N)\n",
    "    \n",
    "    # Threshold of the null calculated and test is rejected if empirical MMD^{2} of the data\n",
    "    # is larger than the threshold\n",
    "    q = np.quantile(shuffled_tests, 1.0-z_alpha)\n",
    "    rej = int(MMD_test > q)\n",
    "    \n",
    "    if return_p:\n",
    "        p_value = 1-(percentileofscore(shuffled_tests,MMD_test)/100)\n",
    "        return rej, p_value\n",
    "    else:\n",
    "        return rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_test(X_samples,Y_samples,gamma,n_tests,n_perms,z_alpha = 0.05,make_K = K_ID,return_p = False):\n",
    "    \"\"\"\n",
    "    Computes multiple two-sample tests and returns the rejection rate\n",
    "    \n",
    "    Parameters:\n",
    "    X_samples - (n_samples*n_tests,n_obs) array of samples from the first distribution \n",
    "    Y_samples - (n_samples*n_tests,n_obs) array of samples from the second distribution \n",
    "    gamma - bandwidth for the kernel\n",
    "    n_tests - number of tests to perform\n",
    "    n_perms - number of permutations performed when bootstrapping the null\n",
    "    z_alpha - rejection threshold of the test\n",
    "    make_K - function called to construct the kernel matrix used to compute the empirical MMD\n",
    "    return_p - option to return the p-value of the test\n",
    "    \n",
    "    Returns:\n",
    "    power - the rate of rejection of the null\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples of each distribution is identified\n",
    "    M = int(X_samples.shape[0]/n_tests)\n",
    "    N = int(Y_samples.shape[0]/n_tests)\n",
    "    rej = np.zeros(n_tests)\n",
    "    \n",
    "    # For each test, extract the data to use and then perform the two-sample test\n",
    "    for t in range(n_tests):\n",
    "        X_t = X_samples[t*M:(t+1)*M,:]\n",
    "        Y_t = Y_samples[t*N:(t+1)*N,:]\n",
    "        rej[t] = two_sample_test(X_t,Y_t,gamma,n_perms,z_alpha = z_alpha,make_K = make_K,return_p = return_p)\n",
    "    \n",
    "    # Compute average rate of rejection\n",
    "    power = np.mean(rej)\n",
    "    return power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berkeley Growth Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berkeley growth data is imported and then the power and size of the kernel two-sample test is empirically investigated. \n",
    "\n",
    "### To measure the test power subsamples from the two groups are taken and the test is performed, this is repeated to compute the power. \n",
    "\n",
    "### To measure the test size disjoint subsamples are taken from the female data set and the test is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subsample(X,n_sub_samples,n_tests,random_state = None):\n",
    "    \"\"\"\n",
    "    For n_tests repeats, takes a random sub-sample without replacement from X of size n_sub_samples\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of function values\n",
    "    n_sub_samples - number of samples samples to take for each repeat\n",
    "    n_tests - number of tests to be later performed, meaning the number of time to take sub-samples\n",
    "    random_state - random seed\n",
    "    \n",
    "    Returns:\n",
    "    rand_samp - (n_sub_samples * n_tests, n_obs) array of randomly subsamples values of X grouped in \n",
    "                n_tests many batches of size n_sub_samples\n",
    "    \"\"\"\n",
    "    rand_samp = np.zeros((n_sub_samples*n_tests,X.shape[1]))\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X_copy = X.copy()\n",
    "    for i in range(n_tests):\n",
    "        rng.shuffle(X_copy)\n",
    "        rand_samp[i*n_sub_samples:(i+1)*n_sub_samples,:] = X_copy[:n_sub_samples]\n",
    "    return rand_samp\n",
    "\n",
    "def null_random_subsample(X,n_sub_samples,n_tests,random_state = None):\n",
    "    \"\"\"\n",
    "    For n_tests repeats, takes two disjoint random sub-samples without replacement from X of size n_sub_samples.\n",
    "    For each of the n_tests many sub-arrays of size n_sub_samples, the sub-arrays of the two outputs will be \n",
    "    disjoint, meaning the empirical size of the test can be estimated.\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,n_obs) array of function values\n",
    "    n_sub_samples - number of samples samples to take for each repeat\n",
    "    n_tests - number of tests to be later performed, meaning the number of time to take sub-samples\n",
    "    random_state - random seed\n",
    "    \n",
    "    Returns:\n",
    "    rand_samp_1 - (n_sub_samples * n_tests, n_obs) array of randomly subsamples values of X grouped in \n",
    "                  n_tests many batches of size n_sub_samples\n",
    "    rand_samp_2 - (n_sub_samples * n_tests, n_obs) array of randomly subsamples values of X grouped in \n",
    "                  n_tests many batches of size n_sub_samples\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    rand_samp_1 = np.zeros((n_sub_samples*n_tests,X.shape[1]))\n",
    "    rand_samp_2 = np.zeros((n_sub_samples*n_tests,X.shape[1]))\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X_copy = X.copy()\n",
    "    for i in range(n_tests):\n",
    "        rng.shuffle(X_copy)\n",
    "        rand_samp_1[i*n_sub_samples:(i+1)*n_sub_samples,:] = X_copy[:n_sub_samples]\n",
    "        rand_samp_2[i*n_sub_samples:(i+1)*n_sub_samples,:] = X_copy[n_sub_samples:2*n_sub_samples]\n",
    "    return rand_samp_1,rand_samp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Berkeley growth data, this will need to be changed given your own file path name\n",
    "growth_female = pd.read_csv(\"Berk_Data/berkeley_growth_female.csv\")\n",
    "del growth_female[growth_female.columns[0]]\n",
    "growth_female = np.array(growth_female.T)\n",
    "\n",
    "growth_male = pd.read_csv(\"Berk_Data/berkeley_growth_male.csv\")\n",
    "del growth_male[growth_male.columns[0]]\n",
    "growth_male = np.array(growth_male.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds, number of tests and permutations\n",
    "rng_X = 1234\n",
    "rng_Y = 5678\n",
    "n_tests = 500\n",
    "n_perms = 1000\n",
    "\n",
    "# Range of sample sizes\n",
    "samp_arr = np.array([5,10,15,20])\n",
    "\n",
    "# Set bandwidth parameter, -1 causes median heuristic to be used\n",
    "gamma = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b687c7a43a4df8a9ee6a32a9451794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.048\n",
      "10 0.054\n",
      "15 0.072\n",
      "20 0.056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samp_powers = np.zeros(len(samp_arr))\n",
    "\n",
    "# Iterates over every sample size in samp_arr\n",
    "for i,samp_size in enumerate(tqdm(samp_arr)):\n",
    "    # Extracts the random sub-samples\n",
    "    X = random_subsample(growth_male,samp_size,n_tests,random_state = rng_X)\n",
    "    Y = random_subsample(growth_female,samp_size,n_tests,random_state = rng_Y)\n",
    "    \n",
    "    # To compute the size instead of the power, replace the two lines above with the following line\n",
    "    X,Y = null_random_subsample(growth_female,samp_size,n_tests,random_state = rng_X)\n",
    "    \n",
    "    # For each of the different scenarios ID, FPCA, SQR, CEXP, POLY alter the code as follows:\n",
    "    # ID: Use K_ID in power_test\n",
    "    # FPCA: Use K_FPCA in power_test\n",
    "    # SQR: Use K_SQR in power_test\n",
    "    # COV: Use K_COV in power_test\n",
    "    # CEXP: Run the following lines before using K_ID in power_test, for given values of n_freqs and l\n",
    "#     n_freqs = 20\n",
    "#     l = np.sqrt(10)\n",
    "#     X = CEXP(X,n_freqs,l) \n",
    "#     Y = CEXP(Y,n_freqs,l) \n",
    "    \n",
    "    samp_powers[i] = power_test(X,Y,gamma,n_tests,n_perms,make_K = K_COV)\n",
    "    print(samp_size,samp_powers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x139824a90>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(samp_arr,samp_powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU Steel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full NEU data set contains six classes of steel defect, we only use the \"Crazing\" and \"Rolled-in Scale\" classes and use the 200x200 pixel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read the 200 by 200 dataset\n",
    "def read200by200DS(directory, prefix):\n",
    "    arrays = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(prefix):\n",
    "            img_array = image.imread(directory+filename)\n",
    "            arrays = arrays + [img_array]\n",
    "        \n",
    "    return np.dstack(arrays) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_k_mat(obs_grid,n_freqs = 20,l=np.sqrt(10)):\n",
    "    return np.array([[cos_exp_kernel(s,t,n_freqs = n_freqs,l=l) for s in obs_grid] for t in obs_grid])\n",
    "                     \n",
    "\n",
    "def CEXP_2D(X,n_freqs = 20,l=np.sqrt(10)):\n",
    "    \"\"\"\n",
    "    Transforms an array of function values using the integral operator induced by the \n",
    "    two-dimensional cos-exp kernel. The function values are assumed to be on [0,1]\n",
    "    \n",
    "    Parameters:\n",
    "    X - (n_samples,dim_1,dim_2) array of 2d data samples\n",
    "    n_freqs - number of frequencies to include in the sum\n",
    "    l - bandwidthlengthscale of the kernel\n",
    "    \n",
    "    Returns:\n",
    "    T - (n_samples,dim_1,dim_2) array of function values where each function has been passed\n",
    "                through the integral operator induced by the two dimensional cos-exp kernel\n",
    "    \"\"\"\n",
    "    T = np.zeros(X.shape)\n",
    "    n_obs = X.shape[1]\n",
    "    obs_grid = np.linspace(0,1,n_obs)\n",
    "    # k_mat is the matrix formed by the one dimensional cos-exp kernel, it is used for the Riemann\n",
    "    # approximation of the two dimensional L^2 integrals\n",
    "    k_mat = make_k_mat(obs_grid,n_freqs = n_freqs,l=l)\n",
    "    for i,x in enumerate(X):\n",
    "        # Riemann approximation of the two dimensional L^2 integral, k_mat appears twice as we are\n",
    "        # using the tensor product of two one dimensional cos-exp kernels\n",
    "        T[i,:,:] = (1/n_obs**2)*np.dot(np.dot(k_mat,x),k_mat)\n",
    "    return T          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds, number of tests and permutations\n",
    "rng_X = 1234\n",
    "rng_Y = 5678\n",
    "n_tests = 500\n",
    "n_perms = 1000\n",
    "\n",
    "# Range of sample sizes\n",
    "samp_arr = np.array([5,10,15,20])\n",
    "\n",
    "# Set bandwidth parameter, -1 causes median heuristic to be used\n",
    "gamma = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caacc1795634e28b088affc5881db05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.038\n",
      "10 0.066\n",
      "15 0.066\n",
      "20 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing and formatting data, will need to be changed given your choice of file storage location\n",
    "topdir = 'steel_data/images200by200//'\n",
    "CR = read200by200DS(topdir, 'Cr')\n",
    "RS = read200by200DS(topdir, 'RS')\n",
    "CR = np.moveaxis(CR,2,0)\n",
    "RS = np.moveaxis(RS,2,0)\n",
    "\n",
    "samp_powers = np.zeros(len(samp_arr))\n",
    "\n",
    "# For each of the different scenarios ID, FPCA, SQR, CEXP, POLY alter the code as follows:\n",
    "    # ID: Use K_ID in power_test\n",
    "    # FPCA: Use K_FPCA in power_test\n",
    "    # SQR: Use K_SQR in power_test\n",
    "    # COV: Use K_COV in power_test\n",
    "    # CEXP: Uncomment the two following lines with specified values of n_freqs and l and use K_ID in power_test\n",
    "# CR = CEXP_2D(CR,n_freqs = 20,l = np.sqrt(10)/200) \n",
    "# RS = CEXP_2D(RS,n_freqs = 20,l = np.sqrt(10)/200) \n",
    "\n",
    "\n",
    "# Flatten the data since the Riemann approximations of the L^2 integrals still hold when data is \n",
    "# flattened and it means we can re-use the same functions as in the 1d time series examples\n",
    "CR = np.reshape(CR,(CR.shape[0],CR.shape[1]*CR.shape[2])) \n",
    "RS = np.reshape(RS,(RS.shape[0],RS.shape[1]*RS.shape[2])) \n",
    "\n",
    "# Iterates over every sample size in samp_arr\n",
    "for i,samp_size in enumerate(tqdm(samp_arr)):\n",
    "    # Extracts the random sub-samples\n",
    "#     X = random_subsample(CR,samp_size,n_tests,random_state = rng_X)\n",
    "#     Y = random_subsample(RS,samp_size,n_tests,random_state = rng_Y)\n",
    "\n",
    "    # To compute the size instead of the power, replace the two lines above with the following line\n",
    "    X,Y = null_random_subsample(RS,samp_size,n_tests,random_state = rng_X)\n",
    "    \n",
    "    samp_powers[i] = power_test(X,Y,gamma,n_tests,n_perms,make_K = K_COV)\n",
    "    print(samp_size,samp_powers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
